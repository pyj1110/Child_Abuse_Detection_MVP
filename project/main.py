import os
import cv2
import pandas as pd
import numpy as np
import time
from tqdm import tqdm

try:
    from project.M1 import ModelInference
    from project.M2 import FeatureExtractor
    from project.M3 import AbuseDetector
except ImportError:
    from M1 import ModelInference
    from M2 import FeatureExtractor
    from M3 import AbuseDetector

def process_video(video_path, model_path, output_dir, progress_callback=None):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì§„í–‰ë¥  ì½œë°± ì§€ì›"""
    
    # 1. ì´ˆê¸°í™”
    os.makedirs(output_dir, exist_ok=True)
    
    # ëª¨ë¸ ê²½ë¡œ ì ˆëŒ€ ê²½ë¡œ ë³€í™˜
    if not os.path.isabs(model_path):
        model_path = os.path.abspath(model_path)
        
    m1 = ModelInference(model_path)
    m2 = FeatureExtractor()
    m3 = AbuseDetector()
    
    # Step 1: ì¶”ë¡  ë° íŠ¸ë˜í‚¹
    if progress_callback:
        progress_callback(0, "Step 1: ì¶”ë¡  ë° íŠ¸ë˜í‚¹ ì¤€ë¹„ì¤‘...")
    
    print("\n" + "="*50)
    print("Step 1: ì¶”ë¡  ë° íŠ¸ë˜í‚¹ ì¤‘...")
    print("="*50)
    
    start_time = time.time()
    
    # ì§„í–‰ë¥  ì½œë°± ì„¤ì •
    if progress_callback:
        def step1_progress(progress, status):
            # Step 1ì˜ ì§„í–‰ë¥ ì„ 0-70%ë¡œ ë§¤í•‘
            mapped_progress = progress * 0.7
            progress_callback(mapped_progress, status)
        m1.set_progress_callback(step1_progress)
    
    preds_df = m1.run_inference(video_path)
    inference_time = time.time() - start_time
    print(f"\nâœ… ì¶”ë¡  ì™„ë£Œ: {len(preds_df)}ê°œì˜ ê°ì§€ ê²°ê³¼ ({inference_time:.2f}ì´ˆ ì†Œìš”)")
    
    if preds_df.empty:
        print("ê²½ê³ : ì¶”ë¡  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    # Step 2: í”¼ì²˜ ì¶”ì¶œ
    if progress_callback:
        progress_callback(0.7, "Step 2: í”¼ì²˜ ì¶”ì¶œ ì¤‘...")
    
    print("\n" + "="*50)
    print("Step 2: í”¼ì²˜ ì¶”ì¶œ ì¤‘...")
    print("="*50)
    
    start_time = time.time()
    features_df = m2.process(preds_df)
    feature_time = time.time() - start_time
    print(f"\nâœ… í”¼ì²˜ ì¶”ì¶œ ì™„ë£Œ ({feature_time:.2f}ì´ˆ ì†Œìš”)")
    
    # Step 3: ê·œì¹™ ê¸°ë°˜ íƒì§€
    if progress_callback:
        progress_callback(0.85, "Step 3: ê·œì¹™ ê¸°ë°˜ íƒì§€ ì¤‘...")
    
    print("\n" + "="*50)
    print("Step 3: ê·œì¹™ ê¸°ë°˜ íƒì§€ ì¤‘...")
    print("="*50)
    
    start_time = time.time()
    alerts_df = m3.detect(features_df)
    detection_time = time.time() - start_time
    
    # íƒì§€ ê²°ê³¼ ìš”ì•½
    if alerts_df is not None and not alerts_df.empty:
        suspicious_count = len(alerts_df[alerts_df['type'] == 'suspicious'])
        abuse_count = len(alerts_df[alerts_df['type'] == 'abuse_report'])
        print(f"\nâœ… ê·œì¹™ ê¸°ë°˜ íƒì§€ ì™„ë£Œ ({detection_time:.2f}ì´ˆ ì†Œìš”)")
        print(f"   â€¢ ì˜ì‹¬ í–‰ë™: {suspicious_count}ê±´")
        print(f"   â€¢ í•™ëŒ€ ì‹ ê³  ì•ŒëŒ: {abuse_count}ê±´")
    else:
        print(f"\nâœ… ê·œì¹™ ê¸°ë°˜ íƒì§€ ì™„ë£Œ ({detection_time:.2f}ì´ˆ ì†Œìš”)")
        print("   â€¢ ê°ì§€ëœ ì•Œë¦¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ê²°ê³¼ ì €ì¥
    preds_path = os.path.join(output_dir, 'preds.csv')
    alerts_path = os.path.join(output_dir, 'alerts.csv')
    
    features_df.to_csv(preds_path, index=False)
    alerts_df.to_csv(alerts_path, index=False)

    print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {preds_path}, {alerts_path}")
    
    # ìµœì¢… ì™„ë£Œ
    if progress_callback:
        progress_callback(1.0, "ë¶„ì„ ì™„ë£Œ!")
    
    return features_df, alerts_df

def create_annotated_video(video_path, features_df, alerts_df, output_path, progress_callback=None):
    """ê²°ê³¼ ì‹œê°í™” ë¹„ë””ì˜¤ ìƒì„± - ë©”ëª¨ë¦¬ ìµœì í™” ë° ì˜ìƒ í’ˆì§ˆ ê°œì„ """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("ì˜¤ë¥˜: ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # ë¹„ë””ì˜¤ ì •ë³´ í™•ì¸
    if total_frames <= 0:
        print("ì˜¤ë¥˜: ë¹„ë””ì˜¤ í”„ë ˆì„ ìˆ˜ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        cap.release()
        return None
    
    # í•´ìƒë„ ìœ ì§€ (í’ˆì§ˆ ì €í•˜ ë°©ì§€)
    width = original_width
    height = original_height
    
    # ë¹„ë””ì˜¤ ì½”ë± ì„¤ì • (í˜¸í™˜ì„± ê°œì„ )
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # mp4v ì½”ë± ì‚¬ìš©
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    if not out.isOpened():
        print(f"ì˜¤ë¥˜: ë¹„ë””ì˜¤ ë¼ì´í„°ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì½”ë±: mp4v, í•´ìƒë„: {width}x{height}, FPS: {fps}")
        cap.release()
        return None
    
    # 15ê°œ í‚¤í¬ì¸íŠ¸ ì—°ê²°ì„  ì •ì˜
    SKELETON_CONNECTIONS = [
        (0, 1), (0, 2), (1, 3), (2, 4),          # ì–¼êµ´
        (5, 6), (5, 7), (7, 9), (6, 8), (8, 10), # íŒ”
        (5, 11), (6, 12), (11, 12),               # ëª¸í†µ
        (11, 13), (13, 14), (12, 14)              # ë‹¤ë¦¬
    ]
    
    # ID-í´ë˜ìŠ¤ ë§¤í•‘ ìƒì„± (track_id -> class)
    print("\nğŸ” ID-í´ë˜ìŠ¤ ë§¤í•‘ í™•ì¸ ì¤‘...")
    id_class_mapping = {}
    if not features_df.empty:
        for track_id in features_df['track_id'].unique():
            track_data = features_df[features_df['track_id'] == track_id]
            if not track_data.empty:
                # ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” í´ë˜ìŠ¤ ì‚¬ìš©
                mode_class = track_data['class'].mode()
                if not mode_class.empty:
                    id_class_mapping[int(track_id)] = int(mode_class.iloc[0])
                    class_name = "ì„±ì¸" if mode_class.iloc[0] == 1 else "ì•„ë™"
                    print(f"   ID {track_id} -> í´ë˜ìŠ¤ {mode_class.iloc[0]} ({class_name})")
    
    print("\n" + "="*50)
    print("ğŸ¬ ì£¼ì„ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
    print("="*50)
    
    frame_idx = 0
    
    # âœ… tqdm ì œê±°: ì§ì ‘ ì§„í–‰ë¥  í‘œì‹œ
    print(f"ğŸ“Š ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    last_reported_percent = -1
    
    # í”„ë ˆì„ë³„ ìƒ‰ìƒ ìºì‹œ
    frame_cache = {}
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret: 
                break
            
            # í˜„ì¬ í”„ë ˆì„ ë°ì´í„°
            f_data = features_df[features_df['frame'] == frame_idx]
            
            # í˜„ì¬ í”„ë ˆì„ì´ Alert êµ¬ê°„ì¸ì§€ í™•ì¸
            is_alert = False
            alert_type = ""
            alert_details = ""
            confidence_percent = 0
            
            if alerts_df is not None and not alerts_df.empty:
                active_alerts = alerts_df[(alerts_df['start_frame'] <= frame_idx) & 
                                          (alerts_df['end_frame'] >= frame_idx)]
                if not active_alerts.empty:
                    is_alert = True
                    # ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ì˜ ê²½ê³  ì •ë³´ ì‚¬ìš©
                    highest_alert = active_alerts.loc[active_alerts['confidence'].idxmax()]
                    alert_type = highest_alert['type']
                    confidence_percent = int(highest_alert['confidence'] * 100)

            # ì‹œê°í™”: ê²½ê³  ë©”ì‹œì§€
            if is_alert:
                if alert_type == 'abuse_report':
                    # í•™ëŒ€ ì‹ ê³  ì•ŒëŒ - ë¹¨ê°„ìƒ‰
                    overlay = frame.copy()
                    cv2.rectangle(overlay, (0, 0), (width, 100), (0, 0, 255), -1)
                    cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
                    
                    # ìˆ˜ì •: 'CHILD ABUSE REPORT' í…ìŠ¤íŠ¸ë¥¼ ë‹¨ìˆœí•œ ê²½ê³ ë¡œ ë³€ê²½
                    alert_text = "ABUSE DETECTED"
                    alert_details = f"Immediate action required - Confidence: {confidence_percent}%"
                    
                    # ì£¼ ê²½ê³  ë¬¸êµ¬ (ë¬¼ìŒí‘œ ì—†ì´)
                    cv2.putText(frame, alert_text, 
                               (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
                    
                    # ìƒì„¸ ì •ë³´
                    cv2.putText(frame, alert_details, 
                               (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                    
                    # ê²½ê³  ì•„ì´ì½˜ ì¶”ê°€ (ì„ íƒì‚¬í•­)
                    # cv2.putText(frame, "WARNING", (width - 150, 50), 
                    #            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
                else:
                    # ì˜ì‹¬ í–‰ë™ - ì£¼í™©ìƒ‰
                    overlay = frame.copy()
                    cv2.rectangle(overlay, (0, 0), (width, 80), (0, 165, 255), -1)
                    cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
                    
                    alert_text = "Suspicious Behavior"
                    alert_details = f"Suspicion Level: {confidence_percent}%"
                    
                    # ì£¼ ê²½ê³  ë¬¸êµ¬
                    cv2.putText(frame, alert_text, 
                               (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
                    
                    # ìƒì„¸ ì •ë³´
                    cv2.putText(frame, alert_details, 
                               (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            # ì‹œê°í™”: ìŠ¤ì¼ˆë ˆí†¤ ë° ë°•ìŠ¤
            for _, row in f_data.iterrows():
                kpts = row['keypoints']
                if isinstance(kpts, str):
                    kpts = eval(kpts)
                
                # í‚¤í¬ì¸íŠ¸ ê°œìˆ˜ì— ë”°ë¼ reshape (15ê°œë¡œ ê³ ì •)
                num_kpts = 15
                kpts = np.array(kpts).reshape(num_kpts, 3)
                
                track_id = int(row['track_id'])
                class_id = int(row['class'])
                
                if track_id > 2:  
                    continue
                
                # IDì— ë”°ë¥¸ ê³ ì • ìƒ‰ìƒ ë° í´ë˜ìŠ¤ ì´ë¦„
                if class_id == 1:  
                    color = (255, 0, 0)      # ë¹¨ê°„ìƒ‰
                    cls_name = "Adult"
                    text_color = (255, 255, 255)
                else:  
                    color = (0, 255, 0)      # ì´ˆë¡ìƒ‰
                    cls_name = "Child"
                    text_color = (0, 0, 0)
                
                # BBox ê·¸ë¦¬ê¸° (ì‹ ë¢°ë„ 0.3 ì´ìƒì¸ í‚¤í¬ì¸íŠ¸ ê¸°ì¤€)
                valid_kpts = kpts[kpts[:, 2] > 0.3]
                if len(valid_kpts) > 0:
                    x1, y1 = valid_kpts[:, 0].min(), valid_kpts[:, 1].min()
                    x2, y2 = valid_kpts[:, 0].max(), valid_kpts[:, 1].max()
                    
                    # í™”ë©´ ë°–ìœ¼ë¡œ ë‚˜ê°€ëŠ” ê²ƒ ë°©ì§€
                    x1, y1 = max(0, x1), max(0, y1)
                    x2, y2 = min(width, x2), min(height, y2)

                    # BBox ê·¸ë¦¬ê¸° (ë‘¥ê·¼ ëª¨ì„œë¦¬)
                    thickness = 3
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)
                    
                    # ë¼ë²¨ ë°°ê²½
                    label = f"{cls_name} ID:{track_id}"
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
                    label_bg_end = (int(x1) + label_size[0] + 10, int(y1))
                    label_bg_start = (int(x1), int(y1) - label_size[1] - 10)
                    
                    # ë°°ê²½ì´ í™”ë©´ ìœ„ìª½ì„ ë„˜ì§€ ì•Šë„ë¡ ì¡°ì •
                    if label_bg_start[1] < 0:
                        label_bg_start = (int(x1), 0)
                        label_bg_end = (int(x1) + label_size[0] + 10, label_size[1] + 5)
                    
                    cv2.rectangle(frame, label_bg_start, label_bg_end, color, -1)
                    
                    # ë¼ë²¨ í…ìŠ¤íŠ¸
                    text_pos = (int(x1) + 5, int(y1) - 5 if y1 - 5 > 0 else label_size[1])
                    cv2.putText(frame, label, text_pos,
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, text_color, 2)

                # ìŠ¤ì¼ˆë ˆí†¤ í‚¤í¬ì¸íŠ¸ ì‹œê°í™”
                # ì—°ê²°ì„  ê·¸ë¦¬ê¸°
                for connection in SKELETON_CONNECTIONS:
                    start_idx, end_idx = connection
                    if (start_idx < len(kpts) and end_idx < len(kpts) and 
                        kpts[start_idx][2] > 0.3 and kpts[end_idx][2] > 0.3):
                        
                        start_point = (int(kpts[start_idx][0]), int(kpts[start_idx][1]))
                        end_point = (int(kpts[end_idx][0]), int(kpts[end_idx][1]))
                        
                        # ì—°ê²°ì„  ê·¸ë¦¬ê¸°
                        cv2.line(frame, start_point, end_point, color, 3)
                
                # í‚¤í¬ì¸íŠ¸ ì  ê·¸ë¦¬ê¸°
                for i in range(min(len(kpts), 15)):
                    if kpts[i][2] > 0.3:
                        center = (int(kpts[i][0]), int(kpts[i][1]))
                        # í‚¤í¬ì¸íŠ¸ ì 
                        cv2.circle(frame, center, 6, color, -1)
                        # í‚¤í¬ì¸íŠ¸ ì  í…Œë‘ë¦¬
                        cv2.circle(frame, center, 6, text_color, 1)
            
            # í”„ë ˆì„ ìºì‹œì— ì €ì¥ (ë©”ëª¨ë¦¬ ìµœì í™”)
            frame_cache[frame_idx] = frame.copy()
            
            # ì£¼ê¸°ì ìœ¼ë¡œ í”„ë ˆì„ ì“°ê¸° (ë©”ëª¨ë¦¬ ê´€ë¦¬)
            if frame_idx % 10 == 0:
                for cached_idx in sorted(frame_cache.keys()):
                    out.write(frame_cache[cached_idx])
                frame_cache.clear()
            
            frame_idx += 1
            
            # ì§„í–‰ë¥  í‘œì‹œ (5% ë‹¨ìœ„)
            if frame_idx % 100 == 0 or frame_idx == total_frames:
                progress = frame_idx / total_frames
                percent = int(progress * 100)
                if percent != last_reported_percent and percent % 5 == 0:
                    print(f"   ì§„í–‰ë¥ : {percent}% ({frame_idx}/{total_frames})")
                    last_reported_percent = percent
                
                # ì§„í–‰ë¥  ì½œë°± í˜¸ì¶œ
                if progress_callback:
                    progress_callback(progress, f"ë¹„ë””ì˜¤ ìƒì„± ì¤‘... ({frame_idx}/{total_frames})")
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬: ë§¤ 100í”„ë ˆì„ë§ˆë‹¤ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
            if frame_idx % 100 == 0:
                import gc
                gc.collect()
    
    except Exception as e:
        print(f"ë¹„ë””ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    finally:
        # ë‚¨ì€ í”„ë ˆì„ ì“°ê¸°
        for cached_idx in sorted(frame_cache.keys()):
            out.write(frame_cache[cached_idx])
        
        cap.release()
        out.release()
    
    print("   ì§„í–‰ë¥ : 100% (ì™„ë£Œ)")
    
    # ë¹„ë””ì˜¤ íŒŒì¼ í™•ì¸
    if os.path.exists(output_path):
        file_size = os.path.getsize(output_path) / (1024 * 1024)  # MB ë‹¨ìœ„
        print(f"\nâœ… ì£¼ì„ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
        print(f"   íŒŒì¼ í¬ê¸°: {file_size:.1f} MB")
        print(f"   í•´ìƒë„: {width}x{height}, FPS: {fps}")
    else:
        print(f"\nâŒ ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨: {output_path}")
    
    if progress_callback:
        progress_callback(1.0, "ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ!")
    
    return output_path

def create_alert_clips(video_path, alerts_df, output_dir):
    """í•™ëŒ€ ì‹ ê³  ì•ŒëŒë§Œ ë”°ë¡œ í´ë¦½ìœ¼ë¡œ ìƒì„± (1.5~3ì´ˆ)"""
    if alerts_df is None or alerts_df.empty:
        print("\nâš ï¸ ìƒì„±í•  í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # í•™ëŒ€ ì‹ ê³  ì•ŒëŒë§Œ í•„í„°ë§
    abuse_reports = alerts_df[alerts_df['type'] == 'abuse_report']
    if abuse_reports.empty:
        print("\nâš ï¸ í•™ëŒ€ ì‹ ê³  ì•ŒëŒ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("ì˜¤ë¥˜: ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    # 1.5~3ì´ˆ ë‚´ì™¸ í´ë¦½ ìƒì„± (fps ê¸°ì¤€)
    min_clip_frames = int(fps * 1.5)  # ìµœì†Œ 1.5ì´ˆ
    max_clip_frames = int(fps * 3)    # ìµœëŒ€ 3ì´ˆ
    
    # í•´ìƒë„ ìœ ì§€ (í’ˆì§ˆ ì €í•˜ ë°©ì§€)
    width = original_width
    height = original_height
    
    clip_paths = []
    
    print("\n" + "="*50)
    print("ğŸš¨ í•™ëŒ€ ì‹ ê³  ì•ŒëŒ í´ë¦½ ìƒì„± ì¤‘...")
    print("="*50)
    
    for i, alert in abuse_reports.iterrows():
        start_frame = int(alert['start_frame'])
        confidence = alert['confidence']
        
        # í´ë¦½ ê¸¸ì´ ê²°ì • (1.5~3ì´ˆ)
        clip_duration_frames = min(
            max(min_clip_frames, int(fps * 2.0)),  # ê¸°ë³¸ 2.0ì´ˆ
            max_clip_frames
        )
        end_frame = start_frame + clip_duration_frames
        
        # í´ë¦½ íŒŒì¼ëª… ìƒì„±
        clip_filename = f"abuse_report_{i+1}_conf_{confidence:.2f}.mp4"
        clip_path = os.path.join(output_dir, clip_filename)
        
        # ë¹„ë””ì˜¤ ë¼ì´í„° ì„¤ì •
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(clip_path, fourcc, fps, (width, height))
        
        if not out.isOpened():
            print(f"ì˜¤ë¥˜: í´ë¦½ ë¼ì´í„°ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {clip_path}")
            continue
        
        # í•´ë‹¹ í”„ë ˆì„ ë²”ìœ„ë¡œ ì´ë™
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        
        frames_to_capture = clip_duration_frames
        
        for frame_idx in range(frames_to_capture):
            ret, frame = cap.read()
            if not ret:
                break
                
            # ë¹¨ê°„ìƒ‰ ì•Œë¦¼ ë°°ê²½ (íˆ¬ëª…ë„ ì ìš©)
            overlay = frame.copy()
            cv2.rectangle(overlay, (0, 0), (width, 120), (0, 0, 255), -1)
            cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
            
            # ì˜ì–´ ì•Œë¦¼ ë¬¸êµ¬
            cv2.putText(frame, "CHILD ABUSE REPORT", 
                       (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
            cv2.putText(frame, "IMMEDIATE ACTION REQUIRED", 
                       (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, f"Confidence: {confidence:.1%}", 
                       (20, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            # ê²½ê³  ì•„ì´ì½˜
            cv2.putText(frame, "âš ï¸", (width - 60, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 255, 255), 3)
            
            out.write(frame)
        
        out.release()
        
        if os.path.exists(clip_path):
            file_size = os.path.getsize(clip_path) / (1024 * 1024)
            clip_paths.append(clip_path)
            print(f"âœ… í•™ëŒ€ ì‹ ê³  í´ë¦½ {i+1} ìƒì„± ì™„ë£Œ: {clip_filename} ({clip_duration_frames/fps:.1f}ì´ˆ, {file_size:.1f}MB)")
        else:
            print(f"âŒ í´ë¦½ ìƒì„± ì‹¤íŒ¨: {clip_filename}")
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬
        import gc
        gc.collect()
    
    cap.release()
    
    if clip_paths:
        print(f"\nğŸš¨ ì´ {len(clip_paths)}ê°œì˜ í•™ëŒ€ ì‹ ê³  í´ë¦½ ìƒì„±ë¨")
    else:
        print("\nâš ï¸ ìƒì„±ëœ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    return clip_paths